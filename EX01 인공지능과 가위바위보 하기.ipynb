{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "employed-advice",
   "metadata": {},
   "source": [
    "# **Exploration01 인공지능과 가위바위보 하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-dealer",
   "metadata": {},
   "source": [
    "### **01 데이터 준비 및 확인**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-interview",
   "metadata": {},
   "source": [
    "인공지능과 가위바위보를 하기 위해서는 가위, 바위, 보 사진이 필요하기 때문에 다음 두 가지 사전 작업을 진행해 줍니다. 먼저, [teachable machine 사이트](https://teachablemachine.withgoogle.com/)를 이용해 가위, 바위, 보 사진을 각 100장씩 총 300장 생성합니다. 그리고 나서 사진을 28×28로 사이즈로 변경해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "artistic-delta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "#데이터 준비\n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수는 각 100개씩 총 300개입니다.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor100/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock100/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper100/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "announced-drilling",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[101])\n",
    "print('라벨: ', y_train[101])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-antenna",
   "metadata": {},
   "source": [
    "### **02 모델 설계**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-python",
   "metadata": {},
   "source": [
    "**- 입력부**\n",
    "\n",
    "위에서 x_trian shape을 확인해보니 (28, 28, 3)이었습니다.\n",
    "따라서 model의 첫 layer 입력부의 input_shape은 (28, 28, 3)됩니다.\n",
    "MNIST 숫자 손글씨 데이터셋은 흑백 이미지 데이터로 shape이 (28, 28, 1)이었지만, 가위바위보 이미지는 컬러 데이터이기 때문에 shape이 (28, 28, 3)인 것입니다.\n",
    "\n",
    "**- 출력부**\n",
    "\n",
    "숫자는 0-9까지 10가지로 분류해야하지만 가위바위보는 3가지로 분류하므로, modle의 마지막 layer 출력부를 3으로 해야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "official-nepal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-institute",
   "metadata": {},
   "source": [
    "### **03 모델 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-trust",
   "metadata": {},
   "source": [
    "모델을 학습 시킬때 x_trian을 정규화한 x_train_norm을 사용해야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "alternative-medication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 4s 270ms/step - loss: 1.0900 - accuracy: 0.4118\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0499 - accuracy: 0.4524\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9765 - accuracy: 0.7174\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8405 - accuracy: 0.8451\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7165 - accuracy: 0.7505\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5495 - accuracy: 0.8655\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.7196\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.6512\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7952\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f70bd949150>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-newton",
   "metadata": {},
   "source": [
    "epoch 10을 했을 때 loss는 **0.3726**, accuracy는 **0.8920**로 모델이 학습하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-stationery",
   "metadata": {},
   "source": [
    "### **04 모델 평가**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-aspect",
   "metadata": {},
   "source": [
    "기존의 300개 데이터를 분할하여 학습셋과 평가셋을 마련한 것이 아니기에, 추가로 평가할 데이터를 test 폴더에 업로드하고 평가셋을 만들야 합니다. 평가셋을 만드는 방법은 학습셋을 만드는 방법과 크게 다르지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "saved-experience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test_norm.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "reliable-sheep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 2.8732 - accuracy: 0.3500\n",
      "test_loss: 2.873175859451294 \n",
      "test_accuracy: 0.3499999940395355\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-circulation",
   "metadata": {},
   "source": [
    "test accuracy(**0.34**)가 train accuracy(**0.89**) 보다 상당히 낮게 나왔습니다. 모델을 개선하여 성능을 향상시켜야 되겠습니다. 향상시키는 방향은 다음 3가지로 해보고자합니다.   \n",
    "\n",
    "첫째, 하이퍼 파라미터 변경   \n",
    "둘째, 모델 layer 개수 변경   \n",
    "셋째, 데이터 양 늘리기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-thesaurus",
   "metadata": {},
   "source": [
    "### **05 모델 향상(1) - 하이퍼파라미터 변경**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "reverse-blackberry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0887 - accuracy: 0.4002\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0554 - accuracy: 0.5633\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0056 - accuracy: 0.5196\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9662 - accuracy: 0.5216\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8881 - accuracy: 0.7052\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7611 - accuracy: 0.7330\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.7413\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6210 - accuracy: 0.7224\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.7076\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.8468\n",
      "10/10 - 0s - loss: 2.6145 - accuracy: 0.3633\n",
      "test_loss: 2.6145219802856445 \n",
      "test_accuracy: 0.3633333444595337\n"
     ]
    }
   ],
   "source": [
    "# n_channel_1을 32로 변경\n",
    "\n",
    "n_channel_1=32\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-cambridge",
   "metadata": {},
   "source": [
    "n_channel_1을 32로 변경하니 test_accuracy가 **0.34**에서 **0.36**으로 소폭 높아졌습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "binding-exhibition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0995 - accuracy: 0.3497\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0859 - accuracy: 0.4368\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0392 - accuracy: 0.4969\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9703 - accuracy: 0.7617\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8803 - accuracy: 0.6402\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7738 - accuracy: 0.6474\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.7958\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.7440\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.8554\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7826\n",
      "10/10 - 0s - loss: 2.7070 - accuracy: 0.3500\n",
      "test_loss: 2.7070209980010986 \n",
      "test_accuracy: 0.3499999940395355\n"
     ]
    }
   ],
   "source": [
    "# n_dense를 64로 변경\n",
    "\n",
    "n_channel_1=32\n",
    "n_channel_2=32\n",
    "n_dense=64\n",
    "n_train_epoch=10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-progressive",
   "metadata": {},
   "source": [
    "n_dense를 64로 변경하니 test_accuracy가 **0.36**에서 **0.34**으로 다시 낮아졌습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "acquired-finger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0977 - accuracy: 0.3105\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0712 - accuracy: 0.4841\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0166 - accuracy: 0.8066\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9428 - accuracy: 0.6901\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8587 - accuracy: 0.6171\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6980 - accuracy: 0.7553\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7294 - accuracy: 0.7217\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.7541\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7804\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7755\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7994\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.8257\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8860\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3176 - accuracy: 0.8946\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3045 - accuracy: 0.8846\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2968 - accuracy: 0.8668\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2411 - accuracy: 0.9110\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2367 - accuracy: 0.9351\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2029 - accuracy: 0.9607\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.9088\n",
      "10/10 - 0s - loss: 3.5496 - accuracy: 0.3467\n",
      "test_loss: 3.549572706222534 \n",
      "test_accuracy: 0.3466666638851166\n"
     ]
    }
   ],
   "source": [
    "# n_dense를 초기값 32로 변경, n_train_epoch을 20으로 변경\n",
    "\n",
    "n_channel_1=32\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-sweet",
   "metadata": {},
   "source": [
    "n_train_epoch을 20으로 변경해도 test_accuracy는 **0.34**으로 차이가 없습니다.\n",
    "\n",
    "n_train_epoch을 8, 12, 16 등으로 바꾸어도 비슷한 결과가 나왓습니다.\n",
    "\n",
    "지금 모델에서는 하이퍼파라미터 조정으로 test_accuracy 값에 상승을 기대하기 어려운 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-darwin",
   "metadata": {},
   "source": [
    "### **06 모델 향상(2) - 모델 layer 개수 변경**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-assessment",
   "metadata": {},
   "source": [
    "이번에는 모델 layer 개수를 변경해보려고합니다. layer를 줄여도보고, 늘려도 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "educated-removal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1150 - accuracy: 0.2631\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0564 - accuracy: 0.5276\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9968 - accuracy: 0.6406\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9058 - accuracy: 0.7026\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8266 - accuracy: 0.6971\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.8167\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.7585\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.8042\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.8709\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.8264\n",
      "10/10 - 0s - loss: 1.7389 - accuracy: 0.3167\n",
      "test_loss: 1.7388503551483154 \n",
      "test_accuracy: 0.3166666626930237\n"
     ]
    }
   ],
   "source": [
    "# 모델 layer 7개에서 5개로 감소\n",
    "\n",
    "n_channel_1=16\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "spectacular-cambodia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 5s 236ms/step - loss: 1.0971 - accuracy: 0.3370\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0850 - accuracy: 0.4416\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0729 - accuracy: 0.4639\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0517 - accuracy: 0.4754\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0096 - accuracy: 0.4462\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9224 - accuracy: 0.6578\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7973 - accuracy: 0.6867\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.7142\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7843\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.8013\n",
      "10/10 - 0s - loss: 1.7096 - accuracy: 0.3467\n",
      "test_loss: 1.7095526456832886 \n",
      "test_accuracy: 0.3466666638851166\n"
     ]
    }
   ],
   "source": [
    "# 모델 layer 7개에서 9개로 증가\n",
    "\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_channel_3=32\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-candy",
   "metadata": {},
   "source": [
    "모델의 layer를 5개로 줄여보고, 9개로 늘려봐도 여전히 test_accuracy는 큰 차이가 없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-attention",
   "metadata": {},
   "source": [
    "### **07 모델 향상(3) - 데이터 양 늘리기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-invitation",
   "metadata": {},
   "source": [
    "먼저 데이터의 양을 10배 늘리기 위해 가위, 바위, 보 사진을 각각 1000개씩 준비합니다. 총 3000개의 사진이 준비되었습니다. 이번에는 데이터가 많기 때문에 fundamentals 10. 가랏, 몬스터볼!에서 배운 sklearn의 데이터분할을 이용해 학습셋과 평가셋을 구분해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "conventional-mother",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 이미지 개수는 3000 입니다.\n",
      "X_train shape: (2400, 28, 28, 3)\n",
      "y_train shape: (2400,)\n",
      "X_test shape: (600, 28, 28, 3)\n",
      "y_test shape: (600,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터분할\n",
    "\n",
    "def load_data2(img_path, number_of_data=3000):\n",
    "    img_size=28\n",
    "    color=3\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor1000/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock1000/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper1000/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"총 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(X2, y2)=load_data2(image_dir_path)\n",
    "X2_norm = X2/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2_norm, y2, test_size=0.2, random_state=15)\n",
    "\n",
    "\n",
    "print(\"X_train shape: {}\".format(X2_train.shape))\n",
    "print(\"y_train shape: {}\".format(y2_train.shape))\n",
    "print(\"X_test shape: {}\".format(X2_test.shape))\n",
    "print(\"y_test shape: {}\".format(y2_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bound-magazine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X2_train[2399])\n",
    "print('라벨: ', y2_train[2399])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "experimental-environment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "75/75 [==============================] - 1s 3ms/step - loss: 1.1121 - accuracy: 0.3503\n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.0866 - accuracy: 0.4404\n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.0308 - accuracy: 0.5051\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.8300 - accuracy: 0.6255\n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.7864\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8771\n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8861\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2227 - accuracy: 0.9644\n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1748 - accuracy: 0.9622\n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1180 - accuracy: 0.9822\n",
      "19/19 - 2s - loss: 0.1001 - accuracy: 0.9817\n",
      "test_loss: 0.10009605437517166 \n",
      "test_accuracy: 0.9816666841506958\n"
     ]
    }
   ],
   "source": [
    "# 모델설계 - 모델은 처음 모델을 사용합니다.\n",
    "\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(X2_train, y2_train, epochs=n_train_epoch)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X2_test,y2_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-thursday",
   "metadata": {},
   "source": [
    "test_accuracyrk **0.981**로 대폭 상승하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-repair",
   "metadata": {},
   "source": [
    "이번에는 대전 2기 분들이 각자 촬영하고 공유한 가위, 바위, 보 사진을 모두 모아 데이터로 준비합니다. 가위는 2420개, 바위는 2302개, 보는 2370개가 모여 총 7092개입니다. 처음 300개 데이터 보다 약 23배 데이터가 증가하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "piano-senator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 이미지 개수는 7092 입니다.\n",
      "X_train shape: (5673, 28, 28, 3)\n",
      "y_train shape: (5673,)\n",
      "X_test shape: (1419, 28, 28, 3)\n",
      "y_test shape: (1419,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터분할\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data3(img_path, number_of_data=7092):\n",
    "    img_size=28\n",
    "    color=3\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor2420/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock2302/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper2370/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"총 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(X3, y3)=load_data3(image_dir_path)\n",
    "X3_norm = X3/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3_norm, y3, test_size=0.2, random_state=15)\n",
    "\n",
    "\n",
    "print(\"X_train shape: {}\".format(X3_train.shape))\n",
    "print(\"y_train shape: {}\".format(y3_train.shape))\n",
    "print(\"X_test shape: {}\".format(X3_test.shape))\n",
    "print(\"y_test shape: {}\".format(y3_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "statutory-vault",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X3_train[5672])\n",
    "print('라벨: ', y3_train[5672])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dated-scientist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.1031 - accuracy: 0.9679\n",
      "Epoch 2/10\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0813 - accuracy: 0.9774\n",
      "Epoch 3/10\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0739 - accuracy: 0.9796\n",
      "Epoch 4/10\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0679 - accuracy: 0.9803\n",
      "Epoch 5/10\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0595 - accuracy: 0.9848\n",
      "Epoch 6/10\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0531 - accuracy: 0.9838\n",
      "Epoch 7/10\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0409 - accuracy: 0.9896\n",
      "Epoch 8/10\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0375 - accuracy: 0.9907\n",
      "Epoch 9/10\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0323 - accuracy: 0.9919\n",
      "Epoch 10/10\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0306 - accuracy: 0.9929\n",
      "45/45 - 0s - loss: 0.0621 - accuracy: 0.9845\n",
      "test_loss: 0.06210163235664368 \n",
      "test_accuracy: 0.9844961166381836\n"
     ]
    }
   ],
   "source": [
    "# 모델설계 - 모델은 개선전 처음 모델을 사용해 봅시다.\n",
    "\n",
    "model.fit(X3_train, y3_train, epochs=n_train_epoch)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X3_test,y3_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-smile",
   "metadata": {},
   "source": [
    "test_accuracy가 **0.984**로 조금 더 상승하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-breath",
   "metadata": {},
   "source": [
    "데이터의 양을 늘리니, 학습데이터를 300개만 사용했던 초기 모델의 test accuracy(**0.34**) 보다 상당히 높게 나왔습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-optimization",
   "metadata": {},
   "source": [
    "### **08 정리 및 회고**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-acoustic",
   "metadata": {},
   "source": [
    "- 지금까지 모델을 개선시키기 위한 순서를 정리하면 다음과 같습니다.\n",
    "\n",
    "1. **하이퍼파라미터 변경**   \n",
    "    1) n_channel_1=32/n_channel_2=32/n_dense=32/n_train_epoch=10 : **0.363**           \n",
    "    2) n_channel_1=32/n_channel_2=32/n_dense=64/n_train_epoch=10 : **0.349**           \n",
    "    3) n_channel_1=32/n_channel_2=32/n_dense=32/n_train_epoch=20 : **0.346**\n",
    "      \n",
    "      \n",
    "2. **모델 layer 변경**   \n",
    "    1) layer 7개 -> 5개 축소 : **0.316**   \n",
    "    2) layer 7개 -> 9개 확대 : **0.346**\n",
    "        \n",
    "        \n",
    "3. **데이터 양 증가**   \n",
    "    1) 데이터 3000개(데이터 분할) : **0.981**   \n",
    "    2) 데이터 7092개(데이터 분할) : **0.984**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-shopper",
   "metadata": {},
   "source": [
    "\n",
    "- 모델을 개선시키기 위한 방법으로 하이퍼파라미터를 조정하고 모델의 layer 수를 변경하는 방법은 크게 효과를 보지 못했습니다. 하지만 학습 데이터의 양을 많이 늘리니 test accuracy가 상당히 향상되었습니다. 따라서, 모델을 설계하고 조정하기에 앞서 학습 데이터가 충분한지를 먼저 살피는 것이 중요하다는 것을 알게되었습니다.\n",
    "\n",
    "\n",
    "- 인간의 학습도 많은 양을 반복 숙달 하다보면 어느새 질적인 성장이 이루어지듯, 인공지능 모델도 그러한가 봅니다. :D\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
